{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1522a241",
   "metadata": {},
   "source": [
    "# Data Processing of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734ef521-7db6-4985-bde3-6d1b21f06cd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/LLM-Auditor/myenv/lib/python3.9/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# importing in contracts from CRPWarner\u001b[39;00m\n\u001b[1;32m     11\u001b[0m path_groundTruth_excel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../test-contracts/RugPull/dataset/groundTruth/groundTruth.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m df_groundTruth \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_groundTruth_excel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m list_groundTruth_address \u001b[38;5;241m=\u001b[39m df_groundTruth[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of groundTruth addresses: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(list_groundTruth_address))\n",
      "File \u001b[0;32m~/Code/LLM-Auditor/myenv/lib/python3.9/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/Code/LLM-Auditor/myenv/lib/python3.9/site-packages/pandas/io/excel/_base.py:1567\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m-> 1567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/LLM-Auditor/myenv/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py:552\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    539\u001b[0m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    540\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    541\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m        Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    554\u001b[0m         filepath_or_buffer,\n\u001b[1;32m    555\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    556\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m    557\u001b[0m     )\n",
      "File \u001b[0;32m~/Code/LLM-Auditor/myenv/lib/python3.9/site-packages/pandas/compat/_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "# import\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# importing in contracts from CRPWarner\n",
    "\n",
    "path_groundTruth_excel = '../test-contracts/RugPull/dataset/groundTruth/groundTruth.xlsx'\n",
    "df_groundTruth = pd.read_excel(path_groundTruth_excel, engine='openpyxl')\n",
    "\n",
    "list_groundTruth_address = df_groundTruth['address'].tolist()\n",
    "print('Number of groundTruth addresses: ', len(list_groundTruth_address))\n",
    "\n",
    "# Specify folder paths\n",
    "path_hex_folder = '../test-contracts/RugPull/dataset/groundTruth/hex'\n",
    "path_sol_folder = '../test-contracts/RugPull/dataset/groundTruth/sol'\n",
    "\n",
    "# Get all filenames in the folders without extensions\n",
    "list_filenames_hex = [os.path.splitext(f)[0] for f in os.listdir(path_hex_folder) if os.path.isfile(os.path.join(path_hex_folder, f))]\n",
    "list_filenames_sol = [os.path.splitext(f)[0] for f in os.listdir(path_sol_folder) if os.path.isfile(os.path.join(path_sol_folder, f))]\n",
    "\n",
    "\n",
    "# Find missing hex and sol files\n",
    "def get_missing_addresses(ground_truth_addresses, existing_hex_files, existing_sol_files):\n",
    "    missing_hex_files = []\n",
    "    missing_sol_files = []\n",
    "    for address in ground_truth_addresses:\n",
    "        if address not in existing_hex_files:\n",
    "            missing_hex_files.append(address)\n",
    "        if address not in existing_sol_files:\n",
    "            missing_sol_files.append(address)\n",
    "    return missing_hex_files, missing_sol_files\n",
    "\n",
    "\n",
    "list_hex_lack, list_sol_lack = get_missing_addresses(\n",
    "    list_groundTruth_address, list_filenames_hex, list_filenames_sol)\n",
    "print(\n",
    "    f\"Missing Addresses are: \\n hex:{list_hex_lack}, \\n sol: {list_sol_lack}\")\n",
    "print('The number of missing addresses: hex: ', len(\n",
    "    list_hex_lack), '; sol: ', len(list_sol_lack))\n",
    "\n",
    "# Setup of API keys\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize API keys\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if not OPENAI_API_KEY or not ANTHROPIC_API_KEY:\n",
    "    raise ValueError(\"API keys for OpenAI and Anthropic must be set in the .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa1ff63",
   "metadata": {},
   "source": [
    "# Sample Contract for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e295be-ec2d-4fd1-91dd-d5ebdc4890d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the smart contract code to be audited (example contract code snippet)\n",
    "smart_contract_code = \"\"\"\n",
    "// SPDX-License-Identifier: MIT\n",
    "pragma solidity ^0.8.0;\n",
    "\n",
    "contract ExampleToken {\n",
    "    string public name = \"ExampleToken\";\n",
    "    string public symbol = \"EXT\";\n",
    "    uint8 public decimals = 18;\n",
    "    uint256 public totalSupply;\n",
    "    address public owner;\n",
    "\n",
    "    mapping(address => uint256) public balanceOf;\n",
    "    mapping(address => mapping(address => uint256)) public allowance;\n",
    "\n",
    "    event Transfer(address indexed from, address indexed to, uint256 value);\n",
    "    event Approval(address indexed owner, address indexed spender, uint256 value);\n",
    "\n",
    "    constructor(uint256 _initialSupply) {\n",
    "        owner = msg.sender;\n",
    "        totalSupply = _initialSupply * (10 ** uint256(decimals));\n",
    "        balanceOf[owner] = totalSupply;\n",
    "        emit Transfer(address(0), owner, totalSupply);\n",
    "    }\n",
    "\n",
    "    function transfer(address _to, uint256 _value) public returns (bool success) {\n",
    "        require(balanceOf[msg.sender] >= _value, \"Insufficient balance\");\n",
    "        balanceOf[msg.sender] -= _value;\n",
    "        balanceOf[_to] += _value;\n",
    "        emit Transfer(msg.sender, _to, _value);\n",
    "        return true;\n",
    "    }\n",
    "\n",
    "    function approve(address _spender, uint256 _value) public returns (bool success) {\n",
    "        allowance[msg.sender][_spender] = _value;\n",
    "        emit Approval(msg.sender, _spender, _value);\n",
    "        return true;\n",
    "    }\n",
    "\n",
    "    function transferFrom(address _from, address _to, uint256 _value) public returns (bool success) {\n",
    "        require(_value <= balanceOf[_from], \"Insufficient balance\");\n",
    "        require(_value <= allowance[_from][msg.sender], \"Allowance exceeded\");\n",
    "        balanceOf[_from] -= _value;\n",
    "        balanceOf[_to] += _value;\n",
    "        allowance[_from][msg.sender] -= _value;\n",
    "        emit Transfer(_from, _to, _value);\n",
    "        return true;\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92029949",
   "metadata": {},
   "source": [
    "# GPT 4-O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8625137b",
   "metadata": {},
   "source": [
    "## Running a simple 3 experiment using OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62cbbbd8-f779-4660-95d6-6af283613a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import ChatCompletion, OpenAI\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def open_ai_audit_smart_contract(smart_contract_code):\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "    api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "    if not api_key:\n",
    "        raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "    # Initialize the OpenAI client\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Define the prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI model specialized in auditing smart contracts for potential vulnerabilities, particularly rug pull scenarios. Your task is to analyze the provided smart contract and identify any code patterns or logic flaws that could allow the contract creators to execute a rug pull.\n",
    "\n",
    "    A rug pull is a type of exit scam where the developers of a cryptocurrency project suddenly withdraw all funds from the liquidity pool, leaving investors with worthless tokens. Common indicators of rug pull vulnerabilities include, but are not limited to:\n",
    "\n",
    "    - Centralized control over contract functions.\n",
    "    - The ability to mint or burn tokens without restrictions.\n",
    "    - Unverified external contracts or dependencies.\n",
    "    - Lack of time locks on critical functions.\n",
    "    - Absence of multi-signature requirements for sensitive operations.\n",
    "\n",
    "    Given the following smart contract's code, highlight the specific lines or sections that might be exploited for a rug pull. Provide detailed explanations for each identified vulnerability and suggest possible mitigations or improvements to enhance the contract's security.\n",
    "\n",
    "    Smart Contract Code:\n",
    "    {smart_contract_code}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Make the API call\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",  # Note: Changed from \"gpt-4o\" to \"gpt-4\"\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a smart contract auditor, skilled in identifying vulnerabilities in smart contract code.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=20000\n",
    "        )\n",
    "\n",
    "        # Extract and return the response text\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during the audit: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49d899e-cd5d-46de-bc7c-ce5c6fa72c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audit_smart_contract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudit_reports/audit_result.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Call the function with the example contract\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m audit_result \u001b[38;5;241m=\u001b[39m \u001b[43maudit_smart_contract\u001b[49m(example_contract)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Optionally, save the response to a file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'audit_smart_contract' is not defined"
     ]
    }
   ],
   "source": [
    "output_file = \"audit_reports/audit_result.txt\"\n",
    "\n",
    "# Call the function with the example contract\n",
    "audit_result = open_ai_audit_smart_contract(example_contract)\n",
    "# Optionally, save the response to a file\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d72d90",
   "metadata": {},
   "source": [
    "# Claude 3.5 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac1aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import anthropic\n",
    "\n",
    "output_file = \"audit_reports/claude_audit_result.txt\"\n",
    "def claude_audit_smart_contract(smart_contract_code):\n",
    "    load_dotenv()\n",
    "\n",
    "    # Set the API key using an environment variable\n",
    "    api_key = os.environ.get('ANTHROPIC_API_KEY')\n",
    "    if not api_key:\n",
    "        raise ValueError(\"ANTHROPIC_API_KEY environment variable is not set\")\n",
    "\n",
    "    # Initialize the Anthropic client\n",
    "    client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "    # Define the prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI model specialized in auditing smart contracts for potential vulnerabilities, particularly rug pull scenarios. Your task is to analyze the provided smart contract and identify any code patterns or logic flaws that could allow the contract creators to execute a rug pull.\n",
    "\n",
    "    A rug pull is a type of exit scam where the developers of a cryptocurrency project suddenly withdraw all funds from the liquidity pool, leaving investors with worthless tokens. Common indicators of rug pull vulnerabilities include, but are not limited to:\n",
    "\n",
    "    - Centralized control over contract functions.\n",
    "    - The ability to mint or burn tokens without restrictions.\n",
    "    - Unverified external contracts or dependencies.\n",
    "    - Lack of time locks on critical functions.\n",
    "    - Absence of multi-signature requirements for sensitive operations.\n",
    "\n",
    "    Given the following smart contract's code, highlight the specific lines or sections that might be exploited for a rug pull. Provide detailed explanations for each identified vulnerability and suggest possible mitigations or improvements to enhance the contract's security.\n",
    "\n",
    "    Smart Contract Code:\n",
    "    {smart_contract_code}\n",
    "    \"\"\"\n",
    "\n",
    "    # Make the API call\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=4096,\n",
    "        temperature=0.7,\n",
    "        system=\"You are a smart contract auditor, skilled in identifying vulnerabilities in smart contract code.\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Get the response text\n",
    "    audit_result = response.content[0].text\n",
    "\n",
    "    # Write the response to the output file\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(audit_result)\n",
    "\n",
    "    print(f\"Audit result has been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e615607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audit result has been written to audit_reports/audit_result.txt\n"
     ]
    }
   ],
   "source": [
    "contract = claude_audit_smart_contract(smart_contract_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ee5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44a7a407",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8af86f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for Setup\n",
    "\n",
    "def load_prompts():\n",
    "    \"\"\"Load prompts from the prompts directory.\"\"\"\n",
    "    prompts = {}\n",
    "    prompt_dir = Path('notebooks/prompts/')\n",
    "    basic_prompt_path = prompt_dir / 'basic_ai_prompt.txt'\n",
    "    developer_meta_prompt_path = prompt_dir / 'developer_meta_prompt.txt'\n",
    "\n",
    "    with open(basic_prompt_path, 'r') as file:\n",
    "        prompts['basic'] = file.read()\n",
    "\n",
    "    with open(developer_meta_prompt_path, 'r') as file:\n",
    "        prompts['developer_meta'] = file.read()\n",
    "\n",
    "    return prompts\n",
    "\n",
    "\n",
    "def load_contracts(contract_dir='../test-contracts/RugPull/dataset/groundTruth/'):\n",
    "    \"\"\"Load smart contracts from the specified directory.\"\"\"\n",
    "    contracts = []\n",
    "    for file in os.listdir(contract_dir):\n",
    "        if file.endswith('.sol'):\n",
    "            with open(os.path.join(contract_dir, file), 'r') as f:\n",
    "                contracts.append({'filename': file, 'code': f.read()})\n",
    "    return contracts\n",
    "\n",
    "\n",
    "def initialize_openai_client():\n",
    "    \"\"\"Initialize the OpenAI client.\"\"\"\n",
    "    return openai.ChatCompletion()\n",
    "\n",
    "\n",
    "def initialize_anthropic_client():\n",
    "    \"\"\"Initialize the Anthropic client.\"\"\"\n",
    "    return anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "\n",
    "def audit_contract_openai(model, prompt, contract_code):\n",
    "    \"\"\"Audit a single contract using OpenAI's GPT-4-O model.\"\"\"\n",
    "    client = initialize_openai_client()\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a smart contract auditor.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt.replace(\n",
    "                    \"[Insert smart contract code here]\", contract_code)}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "def audit_contract_anthropic(model, prompt, contract_code):\n",
    "    \"\"\"Audit a single contract using Anthropic's Claude 3.5 Sonnet model.\"\"\"\n",
    "    client = initialize_anthropic_client()\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=model,\n",
    "            prompt=prompt.replace(\n",
    "                \"[Insert smart contract code here]\", contract_code),\n",
    "            max_tokens=3000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.completion\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "def audit_contract_openai(model, prompt, contract_code):\n",
    "    \"\"\"Audit a single contract using OpenAI's GPT-4-O model.\"\"\"\n",
    "    client = initialize_openai_client()\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a smart contract auditor.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt.replace(\n",
    "                    \"[Insert smart contract code here]\", contract_code)}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "def audit_contract_anthropic(model, prompt, contract_code):\n",
    "    \"\"\"Audit a single contract using Anthropic's Claude 3.5 Sonnet model.\"\"\"\n",
    "    client = initialize_anthropic_client()\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=model,\n",
    "            prompt=prompt.replace(\n",
    "                \"[Insert smart contract code here]\", contract_code),\n",
    "            max_tokens=3000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.completion\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "\n",
    "def evaluate_audit(audit_result, known_errors):\n",
    "    \"\"\"\n",
    "    Evaluate whether the audit_result contains the known_errors.\n",
    "    \n",
    "    Parameters:\n",
    "    - audit_result (str): The text output from the audit model.\n",
    "    - known_errors (list): A list of known error descriptions.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if all known errors are found, False otherwise.\n",
    "    \"\"\"\n",
    "    audit_result_lower = audit_result.lower()\n",
    "    return all(error.lower() in audit_result_lower for error in known_errors)\n",
    "\n",
    "\n",
    "def analyze_results(results, total_contracts=20):\n",
    "    \"\"\"Analyze the audit results.\"\"\"\n",
    "    analysis = {}\n",
    "    for model_name in results:\n",
    "        analysis[model_name] = {}\n",
    "        for prompt_type in results[model_name]:\n",
    "            successes = sum(\n",
    "                1 for result in results[model_name][prompt_type] if result['found_errors'])\n",
    "            failure = total_contracts - successes\n",
    "            analysis[model_name][prompt_type] = {\n",
    "                'Success': successes,\n",
    "                'Failure': failure,\n",
    "                'Success Rate (%)': round((successes / total_contracts) * 100, 2)\n",
    "            }\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18701e58",
   "metadata": {},
   "source": [
    "## Performing the audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf5d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prompts and contracts\n",
    "prompts = load_prompts()\n",
    "contracts = load_contracts()\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'GPT4O': 'gpt-4',\n",
    "    'Claude3.5_Sonnet': 'claude-3-5-sonnet-20240620'\n",
    "}\n",
    "\n",
    "# Define prompt types\n",
    "prompt_types = ['basic', 'developer_meta']\n",
    "\n",
    "# Initialize results storage\n",
    "results = {\n",
    "    'GPT4O': {'basic': [], 'developer_meta': []},\n",
    "    'Claude3.5_Sonnet': {'basic': [], 'developer_meta': []}\n",
    "}\n",
    "\n",
    "# Iterate over each contract\n",
    "for contract in contracts[:20]:  # Ensure only 20 contracts are processed\n",
    "    filename = contract['filename']\n",
    "    code = contract['code']\n",
    "\n",
    "    # Retrieve known errors for this contract\n",
    "    # Assuming df_groundTruth has 'address' and 'errors' columns\n",
    "    # Adjust the column names based on your actual DataFrame\n",
    "    known_errors = df_groundTruth[df_groundTruth['address']\n",
    "                                  == filename]['errors'].tolist()\n",
    "\n",
    "    for model_name, model_identifier in models.items():\n",
    "        for prompt_type in prompt_types:\n",
    "            if model_name == 'GPT4O':\n",
    "                audit_result = audit_contract_openai(\n",
    "                    model_identifier, prompts[prompt_type], code)\n",
    "            elif model_name == 'Claude3.5_Sonnet':\n",
    "                audit_result = audit_contract_anthropic(\n",
    "                    model_identifier, prompts[prompt_type], code)\n",
    "            else:\n",
    "                audit_result = \"Unsupported model.\"\n",
    "\n",
    "            # Evaluate the audit result\n",
    "            found_errors = evaluate_audit(audit_result, known_errors)\n",
    "\n",
    "            # Store the result\n",
    "            results[model_name][prompt_type].append({\n",
    "                'contract': filename,\n",
    "                'found_errors': found_errors\n",
    "            })\n",
    "\n",
    "            print(\n",
    "                f\"Completed {model_name} with {prompt_type} on {filename}: {'Success' if found_errors else 'Failure'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb102e6b",
   "metadata": {},
   "source": [
    "### Saving the results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create audit_reports directory if it doesn't exist\n",
    "os.makedirs('audit_reports', exist_ok=True)\n",
    "\n",
    "# Save the results to CSV files\n",
    "for model_name in results:\n",
    "    for prompt_type in results[model_name]:\n",
    "        df_results = pd.DataFrame(results[model_name][prompt_type])\n",
    "        csv_path = f'audit_reports/{model_name.lower()}_{prompt_type}_results.csv'\n",
    "        df_results.to_csv(csv_path, index=False)\n",
    "        print(f\"Results saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67bf37d",
   "metadata": {},
   "source": [
    "### Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(results, total_contracts=20):\n",
    "    \"\"\"Analyze the audit results.\"\"\"\n",
    "    analysis = {}\n",
    "    for model_name in results:\n",
    "        analysis[model_name] = {}\n",
    "        for prompt_type in results[model_name]:\n",
    "            successes = sum(\n",
    "                1 for result in results[model_name][prompt_type] if result['found_errors'])\n",
    "            failure = total_contracts - successes\n",
    "            analysis[model_name][prompt_type] = {\n",
    "                'Success': successes,\n",
    "                'Failure': failure,\n",
    "                'Success Rate (%)': round((successes / total_contracts) * 100, 2)\n",
    "            }\n",
    "    return analysis\n",
    "\n",
    "\n",
    "# Perform analysis\n",
    "analysis = analyze_results(results)\n",
    "\n",
    "# Display the analysis\n",
    "for model, prompt_data in analysis.items():\n",
    "    print(f\"\\nModel: {model}\")\n",
    "    for prompt, data in prompt_data.items():\n",
    "        print(f\"  Prompt: {prompt}\")\n",
    "        for key, value in data.items():\n",
    "            print(f\"    {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
