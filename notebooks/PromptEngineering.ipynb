{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1522a241",
   "metadata": {},
   "source": [
    "# Data Processing of Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbae805",
   "metadata": {},
   "source": [
    "Find missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "734ef521-7db6-4985-bde3-6d1b21f06cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groundTruth addresses:  68\n",
      "Number of missing hex files: 1\n",
      "Number of missing sol files: 1\n",
      "Missing Addresses are: \n",
      " hex: ['0xcb6cd204d783dc8d66896a6def5867d332228d7b'], \n",
      " sol: ['0xcb6cd204d783dc8d66896a6def5867d332228d7b']\n",
      "The number of missing addresses: hex:  1 ; sol:  1\n"
     ]
    }
   ],
   "source": [
    "# Existing imports\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import openai\n",
    "import anthropic\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize API keys\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if not OPENAI_API_KEY or not ANTHROPIC_API_KEY:\n",
    "    raise ValueError(\n",
    "        \"API keys for OpenAI and Anthropic must be set in the .env file.\")\n",
    "\n",
    "# Define paths using Pathlib\n",
    "path_groundTruth_excel = Path(\n",
    "    '../test-contracts/dataset/groundTruth/groundTruth.xlsx')\n",
    "path_hex_folder = Path('../test-contracts/dataset/groundTruth/hex')\n",
    "path_sol_folder = Path('../test-contracts/dataset/groundTruth/sol')\n",
    "\n",
    "# Read the Excel file\n",
    "df_groundTruth = pd.read_excel(path_groundTruth_excel, engine='openpyxl')\n",
    "\n",
    "list_groundTruth_address = df_groundTruth['address'].tolist()\n",
    "print('Number of groundTruth addresses: ', len(list_groundTruth_address))\n",
    "\n",
    "# List filenames without extensions using Pathlib\n",
    "list_filenames_hex = [f.stem for f in path_hex_folder.iterdir() if f.is_file()]\n",
    "list_filenames_sol = [f.stem for f in path_sol_folder.iterdir() if f.is_file()]\n",
    "\n",
    "\n",
    "def get_missing_addresses(\n",
    "    ground_truth_addresses: list,\n",
    "    existing_hex_files: list,\n",
    "    existing_sol_files: list\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Identify missing hex and sol files based on ground truth addresses.\n",
    "\n",
    "    Args:\n",
    "        ground_truth_addresses (list): List of ground truth contract addresses.\n",
    "        existing_hex_files (list): List of existing hex file names (without extensions).\n",
    "        existing_sol_files (list): List of existing sol file names (without extensions).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two lists containing missing hex addresses and missing sol addresses respectively.\n",
    "    \"\"\"\n",
    "    # Convert lists to sets for faster lookup and ensure case-insensitivity\n",
    "    ground_truth_set = {addr.strip().lower()\n",
    "                        for addr in ground_truth_addresses}\n",
    "    existing_hex_set = {fname.strip().lower() for fname in existing_hex_files}\n",
    "    existing_sol_set = {fname.strip().lower() for fname in existing_sol_files}\n",
    "\n",
    "    # Find missing hex and sol addresses using set operations\n",
    "    missing_hex_files = list(ground_truth_set - existing_hex_set)\n",
    "    missing_sol_files = list(ground_truth_set - existing_sol_set)\n",
    "\n",
    "    # Log the missing counts\n",
    "    print(f\"Number of missing hex files: {len(missing_hex_files)}\")\n",
    "    print(f\"Number of missing sol files: {len(missing_sol_files)}\")\n",
    "\n",
    "    return missing_hex_files, missing_sol_files\n",
    "\n",
    "# Find missing hex and sol files using the improved function\n",
    "missing_hex, missing_sol = get_missing_addresses(\n",
    "    list_groundTruth_address,\n",
    "    list_filenames_hex,\n",
    "    list_filenames_sol\n",
    ")\n",
    "\n",
    "print(f\"Missing Addresses are: \\n hex: {missing_hex}, \\n sol: {missing_sol}\")\n",
    "print('The number of missing addresses: hex: ',\n",
    "      len(missing_hex), '; sol: ', len(missing_sol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7a407",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8af86f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30ef7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for Setup\n",
    "\n",
    "def load_prompts():\n",
    "    \"\"\"Load prompts from the prompts directory.\"\"\"\n",
    "    prompts = {}\n",
    "    prompt_dir = Path('prompts/')\n",
    "    basic_prompt_path = prompt_dir / 'basic_ai_prompt.txt'\n",
    "    developer_meta_prompt_path = prompt_dir / 'developer_meta_prompt.txt'\n",
    "\n",
    "    with open(basic_prompt_path, 'r') as file:\n",
    "        prompts['basic'] = file.read()\n",
    "\n",
    "    with open(developer_meta_prompt_path, 'r') as file:\n",
    "        prompts['developer_meta'] = file.read()\n",
    "\n",
    "    return prompts\n",
    "\n",
    "\n",
    "def load_contracts(contract_dir='../test-contracts/dataset/groundTruth/'):\n",
    "    \"\"\"Load smart contracts from the specified directory.\"\"\"\n",
    "    contracts = []\n",
    "    for file in os.listdir(contract_dir):\n",
    "        if file.endswith('.sol'):\n",
    "            with open(os.path.join(contract_dir, file), 'r') as f:\n",
    "                contracts.append({'filename': file, 'code': f.read()})\n",
    "    return contracts\n",
    "\n",
    "\n",
    "def initialize_openai_client():\n",
    "    \"\"\"Initialize the OpenAI client.\"\"\"\n",
    "    return openai.ChatCompletion()\n",
    "\n",
    "\n",
    "def initialize_anthropic_client():\n",
    "    \"\"\"Initialize the Anthropic client.\"\"\"\n",
    "    return anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "\n",
    "def audit_contract_openai(model, prompt, contract_code):\n",
    "    \"\"\"Audit a single contract using OpenAI's GPT-4-O model.\"\"\"\n",
    "    client = initialize_openai_client()\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a smart contract auditor.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt.replace(\n",
    "                    \"[Insert smart contract code here]\", contract_code)}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "def audit_contract_anthropic(model, prompt, contract_code):\n",
    "    \"\"\"Audit a single contract using Anthropic's Claude 3.5 Sonnet model.\"\"\"\n",
    "    client = initialize_anthropic_client()\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=model,\n",
    "            prompt=prompt.replace(\n",
    "                \"[Insert smart contract code here]\", contract_code),\n",
    "            max_tokens=3000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.completion\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "def audit_contract_openai(model, prompt, contract_code):\n",
    "    \"\"\"Audit a single contract using OpenAI's GPT-4-O model.\"\"\"\n",
    "    client = initialize_openai_client()\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a smart contract auditor.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt.replace(\n",
    "                    \"[Insert smart contract code here]\", contract_code)}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "def audit_contract_anthropic(model, prompt, contract_code):\n",
    "    \"\"\"Audit a single contract using Anthropic's Claude 3.5 Sonnet model.\"\"\"\n",
    "    client = initialize_anthropic_client()\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=model,\n",
    "            prompt=prompt.replace(\n",
    "                \"[Insert smart contract code here]\", contract_code),\n",
    "            max_tokens=3000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.completion\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "\n",
    "def evaluate_audit(audit_result, known_errors):\n",
    "    \"\"\"\n",
    "    Evaluate whether the audit_result contains the known_errors.\n",
    "    \n",
    "    Parameters:\n",
    "    - audit_result (str): The text output from the audit model.\n",
    "    - known_errors (list): A list of known error descriptions.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if all known errors are found, False otherwise.\n",
    "    \"\"\"\n",
    "    audit_result_lower = audit_result.lower()\n",
    "    return all(error.lower() in audit_result_lower for error in known_errors)\n",
    "\n",
    "\n",
    "def analyze_results(results, total_contracts=20):\n",
    "    \"\"\"Analyze the audit results.\"\"\"\n",
    "    analysis = {}\n",
    "    for model_name in results:\n",
    "        analysis[model_name] = {}\n",
    "        for prompt_type in results[model_name]:\n",
    "            successes = sum(\n",
    "                1 for result in results[model_name][prompt_type] if result['found_errors'])\n",
    "            failure = total_contracts - successes\n",
    "            analysis[model_name][prompt_type] = {\n",
    "                'Success': successes,\n",
    "                'Failure': failure,\n",
    "                'Success Rate (%)': round((successes / total_contracts) * 100, 2)\n",
    "            }\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18701e58",
   "metadata": {},
   "source": [
    "## Performing the audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf5d35c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../test-contracts/RugPull/dataset/groundTruth/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load prompts and contracts\u001b[39;00m\n\u001b[1;32m      2\u001b[0m prompts \u001b[38;5;241m=\u001b[39m load_prompts()\n\u001b[0;32m----> 3\u001b[0m contracts \u001b[38;5;241m=\u001b[39m \u001b[43mload_contracts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define models\u001b[39;00m\n\u001b[1;32m      6\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPT4O\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClaude3.5_Sonnet\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclaude-3-5-sonnet-20240620\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m }\n",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m, in \u001b[0;36mload_contracts\u001b[0;34m(contract_dir)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load smart contracts from the specified directory.\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m contracts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontract_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.sol\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(contract_dir, file), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../test-contracts/RugPull/dataset/groundTruth/'"
     ]
    }
   ],
   "source": [
    "# Load prompts and contracts\n",
    "prompts = load_prompts()\n",
    "contracts = load_contracts()\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'GPT4O': 'gpt-4o',\n",
    "    'Claude3.5_Sonnet': 'claude-3-5-sonnet-20240620'\n",
    "}\n",
    "\n",
    "# Define prompt types\n",
    "prompt_types = ['basic', 'developer_meta']\n",
    "\n",
    "# Initialize results storage\n",
    "results = {\n",
    "    'GPT4O': {'basic': [], 'developer_meta': []},\n",
    "    'Claude3.5_Sonnet': {'basic': [], 'developer_meta': []}\n",
    "}\n",
    "\n",
    "# Iterate over each contract\n",
    "for contract in contracts[:20]:  # Ensure only 20 contracts are processed\n",
    "    filename = contract['filename']\n",
    "    code = contract['code']\n",
    "    print(filename)\n",
    "    break\n",
    "\n",
    "    # Retrieve known errors for this contract\n",
    "    # Assuming df_groundTruth has 'address' and 'errors' columns\n",
    "    # Adjust the column names based on your actual DataFrame\n",
    "    known_errors = df_groundTruth[df_groundTruth['address']\n",
    "                                  == filename]['errors'].tolist()\n",
    "\n",
    "    for model_name, model_identifier in models.items():\n",
    "        for prompt_type in prompt_types:\n",
    "            if model_name == 'GPT4O':\n",
    "                audit_result = audit_contract_openai(\n",
    "                    model_identifier, prompts[prompt_type], code)\n",
    "            elif model_name == 'Claude3.5_Sonnet':\n",
    "                audit_result = audit_contract_anthropic(\n",
    "                    model_identifier, prompts[prompt_type], code)\n",
    "            else:\n",
    "                audit_result = \"Unsupported model.\"\n",
    "\n",
    "            # Evaluate the audit result\n",
    "            found_errors = evaluate_audit(audit_result, known_errors)\n",
    "\n",
    "            # Store the result\n",
    "            results[model_name][prompt_type].append({\n",
    "                'contract': filename,\n",
    "                'found_errors': found_errors\n",
    "            })\n",
    "\n",
    "            print(\n",
    "                f\"Completed {model_name} with {prompt_type} on {filename}: {'Success' if found_errors else 'Failure'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb102e6b",
   "metadata": {},
   "source": [
    "### Saving the results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create audit_reports directory if it doesn't exist\n",
    "os.makedirs('audit_reports', exist_ok=True)\n",
    "\n",
    "# Save the results to CSV files\n",
    "for model_name in results:\n",
    "    for prompt_type in results[model_name]:\n",
    "        df_results = pd.DataFrame(results[model_name][prompt_type])\n",
    "        csv_path = f'audit_reports/{model_name.lower()}_{prompt_type}_results.csv'\n",
    "        df_results.to_csv(csv_path, index=False)\n",
    "        print(f\"Results saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67bf37d",
   "metadata": {},
   "source": [
    "### Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(results, total_contracts=20):\n",
    "    \"\"\"Analyze the audit results.\"\"\"\n",
    "    analysis = {}\n",
    "    for model_name in results:\n",
    "        analysis[model_name] = {}\n",
    "        for prompt_type in results[model_name]:\n",
    "            successes = sum(\n",
    "                1 for result in results[model_name][prompt_type] if result['found_errors'])\n",
    "            failure = total_contracts - successes\n",
    "            analysis[model_name][prompt_type] = {\n",
    "                'Success': successes,\n",
    "                'Failure': failure,\n",
    "                'Success Rate (%)': round((successes / total_contracts) * 100, 2)\n",
    "            }\n",
    "    return analysis\n",
    "\n",
    "\n",
    "# Perform analysis\n",
    "analysis = analyze_results(results)\n",
    "\n",
    "# Display the analysis\n",
    "for model, prompt_data in analysis.items():\n",
    "    print(f\"\\nModel: {model}\")\n",
    "    for prompt, data in prompt_data.items():\n",
    "        print(f\"  Prompt: {prompt}\")\n",
    "        for key, value in data.items():\n",
    "            print(f\"    {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
